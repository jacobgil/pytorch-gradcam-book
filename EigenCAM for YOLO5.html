
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>EigenCAM for YOLO5 &#8212; Advanced AI explainability with pytorch-gradcam</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Tutorial: Concept Activation Maps" href="Pixel%20Attribution%20for%20embeddings.html" />
    <link rel="prev" title="Tutorial: Class Activation Maps for Object Detection with Faster RCNN" href="Class%20Activation%20Maps%20for%20Object%20Detection%20With%20Faster%20RCNN.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="_static/dff1.jpg" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Advanced AI explainability with pytorch-gradcam</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="introduction.html">
                    Introduction: Advanced Explainable AI for computer vision
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="Class%20Activation%20Maps%20for%20Semantic%20Segmentation.html">
   Tutorial: Class Activation Maps for Semantic Segmentation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Class%20Activation%20Maps%20for%20Object%20Detection%20With%20Faster%20RCNN.html">
   Tutorial: Class Activation Maps for Object Detection with Faster RCNN
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   EigenCAM for YOLO5
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Pixel%20Attribution%20for%20embeddings.html">
   Tutorial: Concept Activation Maps
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="CAM%20Metrics%20And%20Tuning%20Tutorial.html">
   <em>
    May the best explanation win
   </em>
   :
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="vision_transformers.html">
   How does it work with Vision Transformers
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Deep%20Feature%20Factorizations.html">
   Deep Feature Factorizations for better model explainability
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/executablebooks/jupyter-book/master?urlpath=tree/EigenCAM for YOLO5.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="_sources/EigenCAM for YOLO5.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>EigenCAM for YOLO5</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="eigencam-for-yolo5">
<h1>EigenCAM for YOLO5<a class="headerlink" href="#eigencam-for-yolo5" title="Permalink to this headline">#</a></h1>
<p><img alt="image.png" src="https://raw.githubusercontent.com/jacobgil/pytorch-grad-cam/master/examples/yolo_eigencam.png" /></p>
<p>In this tutorial we’re going to see how to use EigenCAM (one of the gradient free methods) for YOLO5.</p>
<p>This is a much simpler version of the tutorial in <a class="reference external" href="https://github.com/jacobgil/pytorch-grad-cam/blob/master/tutorials/Class%20Activation%20Maps%20for%20Object%20Detection%20With%20Faster%20RCNN.ipynb">https://github.com/jacobgil/pytorch-grad-cam/blob/master/tutorials/Class Activation Maps for Object Detection With Faster RCNN.ipynb</a>
adapted for YOLO5.</p>
<p>If you wanted to use other methods like AblationCAM, you can use the other tutorial.</p>
<p>As a reminder from the tutorial above, we’re going to use gradient free methods for object detection, since most frameworks won’t support computing gradients.</p>
<p>We’re going to use the YOLO5 model from ultralytics</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>model = torch.hub.load(&#39;ultralytics/yolov5&#39;, &#39;yolov5s&#39;, pretrained=True)`
</pre></div>
</div>
<p>As you recall, when adapting this library to new architectures, there are three main things you need to think about:</p>
<ul>
<li><p><strong>The reshape transform</strong>.
This is used to get the activations from the model and process them so they are in 2D format.
Sometimes the layers will not output tensors, for example, but tuples of tensors.
So we need a function that knows to dig into the output and find our 2D activation.</p>
<p>In the case of YOLO5, no need for this, we’re getting a 2D spatial tensor.</p>
</li>
<li><p><strong>The target function</strong> that guides our class activation map.</p>
<p>In the case of EigenCAM, there is no target function. We’re going to do PCA on the 2D activations.</p>
<p>If we would use another method like AblationCAM we would need this, and then you can look at the faster-rcnn tutorial above.</p>
</li>
<li><p><strong>The target layer</strong> to extract the 2D activations from. We’re going to use the second last layer. The last layer in YOLO5    outputs the detections, so instead we’re going to use the one before it.
After printing the model and playing with it, this is in</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">model</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span>
</pre></div>
</div>
</li>
</ul>
<p>First lets write some boiler plate code for doing a forward pass on the image, and displaying the detections:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">simplefilter</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>
<span class="kn">import</span> <span class="nn">torch</span>    
<span class="kn">import</span> <span class="nn">cv2</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">requests</span>
<span class="kn">import</span> <span class="nn">torchvision.transforms</span> <span class="k">as</span> <span class="nn">transforms</span>
<span class="kn">from</span> <span class="nn">pytorch_grad_cam</span> <span class="kn">import</span> <span class="n">EigenCAM</span>
<span class="kn">from</span> <span class="nn">pytorch_grad_cam.utils.image</span> <span class="kn">import</span> <span class="n">show_cam_on_image</span><span class="p">,</span> <span class="n">scale_cam_image</span>
<span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>

<span class="n">COLORS</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">255</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">80</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>

<span class="k">def</span> <span class="nf">parse_detections</span><span class="p">(</span><span class="n">results</span><span class="p">):</span>
    <span class="n">detections</span> <span class="o">=</span> <span class="n">results</span><span class="o">.</span><span class="n">pandas</span><span class="p">()</span><span class="o">.</span><span class="n">xyxy</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">detections</span> <span class="o">=</span> <span class="n">detections</span><span class="o">.</span><span class="n">to_dict</span><span class="p">()</span>
    <span class="n">boxes</span><span class="p">,</span> <span class="n">colors</span><span class="p">,</span> <span class="n">names</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[],</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">detections</span><span class="p">[</span><span class="s2">&quot;xmin&quot;</span><span class="p">])):</span>
        <span class="n">confidence</span> <span class="o">=</span> <span class="n">detections</span><span class="p">[</span><span class="s2">&quot;confidence&quot;</span><span class="p">][</span><span class="n">i</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">confidence</span> <span class="o">&lt;</span> <span class="mf">0.2</span><span class="p">:</span>
            <span class="k">continue</span>
        <span class="n">xmin</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">detections</span><span class="p">[</span><span class="s2">&quot;xmin&quot;</span><span class="p">][</span><span class="n">i</span><span class="p">])</span>
        <span class="n">ymin</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">detections</span><span class="p">[</span><span class="s2">&quot;ymin&quot;</span><span class="p">][</span><span class="n">i</span><span class="p">])</span>
        <span class="n">xmax</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">detections</span><span class="p">[</span><span class="s2">&quot;xmax&quot;</span><span class="p">][</span><span class="n">i</span><span class="p">])</span>
        <span class="n">ymax</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">detections</span><span class="p">[</span><span class="s2">&quot;ymax&quot;</span><span class="p">][</span><span class="n">i</span><span class="p">])</span>
        <span class="n">name</span> <span class="o">=</span> <span class="n">detections</span><span class="p">[</span><span class="s2">&quot;name&quot;</span><span class="p">][</span><span class="n">i</span><span class="p">]</span>
        <span class="n">category</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">detections</span><span class="p">[</span><span class="s2">&quot;class&quot;</span><span class="p">][</span><span class="n">i</span><span class="p">])</span>
        <span class="n">color</span> <span class="o">=</span> <span class="n">COLORS</span><span class="p">[</span><span class="n">category</span><span class="p">]</span>

        <span class="n">boxes</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">xmin</span><span class="p">,</span> <span class="n">ymin</span><span class="p">,</span> <span class="n">xmax</span><span class="p">,</span> <span class="n">ymax</span><span class="p">))</span>
        <span class="n">colors</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">color</span><span class="p">)</span>
        <span class="n">names</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">boxes</span><span class="p">,</span> <span class="n">colors</span><span class="p">,</span> <span class="n">names</span>


<span class="k">def</span> <span class="nf">draw_detections</span><span class="p">(</span><span class="n">boxes</span><span class="p">,</span> <span class="n">colors</span><span class="p">,</span> <span class="n">names</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">box</span><span class="p">,</span> <span class="n">color</span><span class="p">,</span> <span class="n">name</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">boxes</span><span class="p">,</span> <span class="n">colors</span><span class="p">,</span> <span class="n">names</span><span class="p">):</span>
        <span class="n">xmin</span><span class="p">,</span> <span class="n">ymin</span><span class="p">,</span> <span class="n">xmax</span><span class="p">,</span> <span class="n">ymax</span> <span class="o">=</span> <span class="n">box</span>
        <span class="n">cv2</span><span class="o">.</span><span class="n">rectangle</span><span class="p">(</span>
            <span class="n">img</span><span class="p">,</span>
            <span class="p">(</span><span class="n">xmin</span><span class="p">,</span> <span class="n">ymin</span><span class="p">),</span>
            <span class="p">(</span><span class="n">xmax</span><span class="p">,</span> <span class="n">ymax</span><span class="p">),</span>
            <span class="n">color</span><span class="p">,</span> 
            <span class="mi">2</span><span class="p">)</span>

        <span class="n">cv2</span><span class="o">.</span><span class="n">putText</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="p">(</span><span class="n">xmin</span><span class="p">,</span> <span class="n">ymin</span> <span class="o">-</span> <span class="mi">5</span><span class="p">),</span>
                    <span class="n">cv2</span><span class="o">.</span><span class="n">FONT_HERSHEY_SIMPLEX</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="n">color</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span>
                    <span class="n">lineType</span><span class="o">=</span><span class="n">cv2</span><span class="o">.</span><span class="n">LINE_AA</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">img</span>


<span class="n">image_url</span> <span class="o">=</span> <span class="s2">&quot;https://upload.wikimedia.org/wikipedia/commons/f/f1/Puppies_</span><span class="si">%284984818141%</span><span class="s2">29.jpg&quot;</span>
<span class="n">img</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">image_url</span><span class="p">,</span> <span class="n">stream</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">raw</span><span class="p">))</span>
<span class="n">img</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">resize</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="p">(</span><span class="mi">640</span><span class="p">,</span> <span class="mi">640</span><span class="p">))</span>
<span class="n">rgb_img</span> <span class="o">=</span> <span class="n">img</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">img</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">(</span><span class="n">img</span><span class="p">)</span> <span class="o">/</span> <span class="mi">255</span>
<span class="n">transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">()</span>
<span class="n">tensor</span> <span class="o">=</span> <span class="n">transform</span><span class="p">(</span><span class="n">img</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">hub</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;ultralytics/yolov5&#39;</span><span class="p">,</span> <span class="s1">&#39;yolov5s&#39;</span><span class="p">,</span> <span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span>
<span class="n">target_layers</span> <span class="o">=</span> <span class="p">[</span><span class="n">model</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">model</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]]</span>

<span class="n">results</span> <span class="o">=</span> <span class="n">model</span><span class="p">([</span><span class="n">rgb_img</span><span class="p">])</span>
<span class="n">boxes</span><span class="p">,</span> <span class="n">colors</span><span class="p">,</span> <span class="n">names</span> <span class="o">=</span> <span class="n">parse_detections</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
<span class="n">detections</span> <span class="o">=</span> <span class="n">draw_detections</span><span class="p">(</span><span class="n">boxes</span><span class="p">,</span> <span class="n">colors</span><span class="p">,</span> <span class="n">names</span><span class="p">,</span> <span class="n">rgb_img</span><span class="o">.</span><span class="n">copy</span><span class="p">())</span>
<span class="n">Image</span><span class="o">.</span><span class="n">fromarray</span><span class="p">(</span><span class="n">detections</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Using cache found in C:\Users\Jacob Gildenblat/.cache\torch\hub\ultralytics_yolov5_master
YOLOv5  2022-4-1 torch 1.10.1+cu102 CUDA:0 (Quadro RTX 5000, 16384MiB)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Downloading https://github.com/ultralytics/yolov5/releases/download/v6.1/yolov5s.pt to yolov5s.pt...
</pre></div>
</div>
<script type="application/vnd.jupyter.widget-view+json">
{"model_id": "953d1674ef354f05aeb35bdc34c961b3", "version_major": 2, "version_minor": 0}
</script><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Fusing layers... 
YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.5 GFLOPs
Adding AutoShape... 
</pre></div>
</div>
<img alt="_images/EigenCAM for YOLO5_1_5.png" src="_images/EigenCAM for YOLO5_1_5.png" />
</div>
</div>
<p>Now lets create our CAM model and run it on the image:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cam</span> <span class="o">=</span> <span class="n">EigenCAM</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">target_layers</span><span class="p">,</span> <span class="n">use_cuda</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">grayscale_cam</span> <span class="o">=</span> <span class="n">cam</span><span class="p">(</span><span class="n">tensor</span><span class="p">)[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:,</span> <span class="p">:]</span>
<span class="n">cam_image</span> <span class="o">=</span> <span class="n">show_cam_on_image</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">grayscale_cam</span><span class="p">,</span> <span class="n">use_rgb</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">Image</span><span class="o">.</span><span class="n">fromarray</span><span class="p">(</span><span class="n">cam_image</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(1, 512, 20, 20)
</pre></div>
</div>
<img alt="_images/EigenCAM for YOLO5_3_1.png" src="_images/EigenCAM for YOLO5_3_1.png" />
</div>
</div>
<p>This contains heatmaps mainly on the dogs, but not only.</p>
<p>Something we can do for object detection is remove heatmap data outside of the bounding boxes, and scale the heatmaps inside every bounding box.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">renormalize_cam_in_bounding_boxes</span><span class="p">(</span><span class="n">boxes</span><span class="p">,</span> <span class="n">colors</span><span class="p">,</span> <span class="n">names</span><span class="p">,</span> <span class="n">image_float_np</span><span class="p">,</span> <span class="n">grayscale_cam</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Normalize the CAM to be in the range [0, 1] </span>
<span class="sd">    inside every bounding boxes, and zero outside of the bounding boxes. &quot;&quot;&quot;</span>
    <span class="n">renormalized_cam</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">grayscale_cam</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">x1</span><span class="p">,</span> <span class="n">y1</span><span class="p">,</span> <span class="n">x2</span><span class="p">,</span> <span class="n">y2</span> <span class="ow">in</span> <span class="n">boxes</span><span class="p">:</span>
        <span class="n">renormalized_cam</span><span class="p">[</span><span class="n">y1</span><span class="p">:</span><span class="n">y2</span><span class="p">,</span> <span class="n">x1</span><span class="p">:</span><span class="n">x2</span><span class="p">]</span> <span class="o">=</span> <span class="n">scale_cam_image</span><span class="p">(</span><span class="n">grayscale_cam</span><span class="p">[</span><span class="n">y1</span><span class="p">:</span><span class="n">y2</span><span class="p">,</span> <span class="n">x1</span><span class="p">:</span><span class="n">x2</span><span class="p">]</span><span class="o">.</span><span class="n">copy</span><span class="p">())</span>    
    <span class="n">renormalized_cam</span> <span class="o">=</span> <span class="n">scale_cam_image</span><span class="p">(</span><span class="n">renormalized_cam</span><span class="p">)</span>
    <span class="n">eigencam_image_renormalized</span> <span class="o">=</span> <span class="n">show_cam_on_image</span><span class="p">(</span><span class="n">image_float_np</span><span class="p">,</span> <span class="n">renormalized_cam</span><span class="p">,</span> <span class="n">use_rgb</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">image_with_bounding_boxes</span> <span class="o">=</span> <span class="n">draw_detections</span><span class="p">(</span><span class="n">boxes</span><span class="p">,</span> <span class="n">colors</span><span class="p">,</span> <span class="n">names</span><span class="p">,</span> <span class="n">eigencam_image_renormalized</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">image_with_bounding_boxes</span>


<span class="n">renormalized_cam_image</span> <span class="o">=</span> <span class="n">renormalize_cam_in_bounding_boxes</span><span class="p">(</span><span class="n">boxes</span><span class="p">,</span> <span class="n">colors</span><span class="p">,</span> <span class="n">names</span><span class="p">,</span> <span class="n">img</span><span class="p">,</span> <span class="n">grayscale_cam</span><span class="p">)</span>
<span class="n">Image</span><span class="o">.</span><span class="n">fromarray</span><span class="p">(</span><span class="n">renormalized_cam_image</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/EigenCAM for YOLO5_5_0.png" src="_images/EigenCAM for YOLO5_5_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Image</span><span class="o">.</span><span class="n">fromarray</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">rgb_img</span><span class="p">,</span> <span class="n">cam_image</span><span class="p">,</span> <span class="n">renormalized_cam_image</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/EigenCAM for YOLO5_6_0.png" src="_images/EigenCAM for YOLO5_6_0.png" />
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="Class%20Activation%20Maps%20for%20Object%20Detection%20With%20Faster%20RCNN.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Tutorial: Class Activation Maps for Object Detection with Faster RCNN</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="Pixel%20Attribution%20for%20embeddings.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Tutorial: Concept Activation Maps</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Jacob Gildenblat<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>