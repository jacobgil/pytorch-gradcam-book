
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>May the best explanation win: &#8212; Advanced AI explainability with pytorch-gradcam</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="How does it work with Vision Transformers" href="vision_transformers.html" />
    <link rel="prev" title="Tutorial: Concept Activation Maps" href="Pixel%20Attribution%20for%20embeddings.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="_static/dff1.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Advanced AI explainability with pytorch-gradcam</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Introduction: Advanced Explainable AI for computer vision
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="Class%20Activation%20Maps%20for%20Semantic%20Segmentation.html">
   Tutorial: Class Activation Maps for Semantic Segmentation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Class%20Activation%20Maps%20for%20Object%20Detection%20With%20Faster%20RCNN.html">
   Tutorial: Class Activation Maps for Object Detection with Faster RCNN
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="EigenCAM%20for%20YOLO5.html">
   EigenCAM for YOLO5
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Pixel%20Attribution%20for%20embeddings.html">
   Tutorial: Concept Activation Maps
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   <em>
    May the best explanation win
   </em>
   :
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="vision_transformers.html">
   How does it work with Vision Transformers
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Deep%20Feature%20Factorizations.html">
   Deep Feature Factorizations for better model explainability
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/executablebooks/jupyter-book/master?urlpath=tree/CAM Metrics And Tuning Tutorial.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="_sources/CAM Metrics And Tuning Tutorial.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   <em>
    May the best explanation win
   </em>
   :
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#a-tutorial-on-benchmarking-and-tuning-model-explanations">
   A tutorial on benchmarking and tuning model explanations
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#evaluating-the-explanations-by-using-them-for-localization">
     Evaluating the explanations by using them for localization
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#evaluating-the-explanations-by-using-them-to-pertubate-the-image-and-predicting-again">
     Evaluating the explanations by using them to pertubate the image and predicting again
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#side-comment-metric-reproducability-and-small-implementation-details">
       Side comment: Metric reproducability and small implementation details
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#we-deleted-important-parts-how-come-it-became-more-confident">
   We deleted important parts, how come it became more confident ?
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#remove-and-retrain-roar">
     Remove and Retrain (ROAR)
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#sanity-checks-for-saliency-metrics">
   Sanity Checks for Saliency Metrics
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#road-remove-and-debias">
   ROAD: Remove and Debias
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>May the best explanation win:</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   <em>
    May the best explanation win
   </em>
   :
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#a-tutorial-on-benchmarking-and-tuning-model-explanations">
   A tutorial on benchmarking and tuning model explanations
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#evaluating-the-explanations-by-using-them-for-localization">
     Evaluating the explanations by using them for localization
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#evaluating-the-explanations-by-using-them-to-pertubate-the-image-and-predicting-again">
     Evaluating the explanations by using them to pertubate the image and predicting again
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#side-comment-metric-reproducability-and-small-implementation-details">
       Side comment: Metric reproducability and small implementation details
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#we-deleted-important-parts-how-come-it-became-more-confident">
   We deleted important parts, how come it became more confident ?
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#remove-and-retrain-roar">
     Remove and Retrain (ROAR)
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#sanity-checks-for-saliency-metrics">
   Sanity Checks for Saliency Metrics
  </a>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#road-remove-and-debias">
   ROAD: Remove and Debias
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="may-the-best-explanation-win">
<h1><em>May the best explanation win</em>:<a class="headerlink" href="#may-the-best-explanation-win" title="Permalink to this headline">#</a></h1>
</div>
<div class="tex2jax_ignore mathjax_ignore section" id="a-tutorial-on-benchmarking-and-tuning-model-explanations">
<h1>A tutorial on benchmarking and tuning model explanations<a class="headerlink" href="#a-tutorial-on-benchmarking-and-tuning-model-explanations" title="Permalink to this headline">#</a></h1>
<p>Which metrics can we use to benchmark different pixel attribution techniques ?</p>
<p>How can we measure if a model explanation is good or bad?</p>
<p>What kind of problems do metrics for model explanatiosn have that we should be aware of ?</p>
<p>And maybe most importantly - how can we use this in practice to tune our explanation ?</p>
<p>In this tutorial you will:</p>
<ul class="simple">
<li><p>Get an overview of different model explanation metrics used (in computer vision) to rank explanation methods.</p></li>
<li><p>Learn how to get the metrics in the pytorch-grad-cam package.</p></li>
<li><p>See examples of how to use these metrics to get better explanations for your images.</p></li>
</ul>
<div class="section" id="evaluating-the-explanations-by-using-them-for-localization">
<h2>Evaluating the explanations by using them for localization<a class="headerlink" href="#evaluating-the-explanations-by-using-them-for-localization" title="Permalink to this headline">#</a></h2>
<p>In 2016 we had the first explainability methods comming out - Class Activation Maps for Networks with Global Averge Pooling (<a class="reference external" href="https://arxiv.org/abs/1512.04150v1">https://arxiv.org/abs/1512.04150v1</a>) and then soon after GradCAM (<a class="reference external" href="https://arxiv.org/abs/1610.02391">https://arxiv.org/abs/1610.02391</a>).</p>
<p>The CAM paper suggested evaluating the explanations by extracting bounding boxes out of them, and comparing to the bounding boxes in the ILSVRC dataset (a subset of Imagenet that has bounding box annotations).
The reasoning here is that if the explanation is good, and correct, it will probably overlap with the actual object.</p>
<p>The bounding box itself is created by just keeping the top 20% highest pixels in the CAM and taking the largest connected compnent.</p>
<p><img alt="image.png" src="_images/bbox.png" />
<em>Image from <a class="reference external" href="https://arxiv.org/abs/1512.04150v1">https://arxiv.org/abs/1512.04150v1</a></em></p>
<p>That’s useful in itself, but it’s just a proxy to what we really want - an explanation that reflects the model decision process.
Imagine that our model is able to identify a cat only by its ears, but didn’t learn anything else. It’s body and fur - irrelevant, our model doesn’t use them.</p>
<p>A good explanation here would highlight what the model is using - the ears.
The overlap between the bounding box of our ideal explanation (around the cat ears) and the cat bounding box would be low.
And we want it to be low, since it’s not using the cat’s body.</p>
<p>Similarly, the Grad-CAM suggested using something called “the pointing game”.
You get the point with the highest value in the CAM, and check if it falls inside a bounding box.
That’s actually a bit better, but still is a limitted metric.</p>
<p>The Score-CAM paper (<a class="reference external" href="https://arxiv.org/abs/1910.01279">https://arxiv.org/abs/1910.01279</a>) suggested evaluating with localization by measuring the total sum of CAM pixels inside the bounding box.</p>
</div>
<div class="section" id="evaluating-the-explanations-by-using-them-to-pertubate-the-image-and-predicting-again">
<h2>Evaluating the explanations by using them to pertubate the image and predicting again<a class="headerlink" href="#evaluating-the-explanations-by-using-them-to-pertubate-the-image-and-predicting-again" title="Permalink to this headline">#</a></h2>
<p>Then came the GradCAM++ paper and offered some metrics that are still widely used.</p>
<p>You multiply the image (before image-net normalization) by the explanation. Only regions that score high will still be visible.
<img alt="image-2.png" src="_images/multimage.png" />
<em>Image from the GradCAM++ paper (<a class="reference external" href="https://arxiv.org/abs/1710.11063">https://arxiv.org/abs/1710.11063</a>)</em></p>
<p>Then you run the new modified “dark” image through the model, and check the new category scores.</p>
<p>The metrics are:</p>
<ul class="simple">
<li><p>(Smaller value is better) Drop in Confidence: What’s the percentage drop of the condience ? (or 0 if the confidence increased).
The confidence is assumed to drop a bit since we’re removing details.</p></li>
<li><p>(Larger value is better) Increase in confidence: In how many of the cases did the confidence increase.</p></li>
</ul>
<p>You might ask: why do we need two complementory metrics, why not just measure the average change in confidence.
I’m not sure, I suspect that would be better.</p>
<p>This is a way of measuring the “fidelity” or “faithfulness” of the explanation. We want a good explanation to reflect the actual regions that the model is using.</p>
<div class="section" id="side-comment-metric-reproducability-and-small-implementation-details">
<h3>Side comment: Metric reproducability and small implementation details<a class="headerlink" href="#side-comment-metric-reproducability-and-small-implementation-details" title="Permalink to this headline">#</a></h3>
<p>In the GradCAM++ paper image above the masked images are black, so it looks like they are multiplying the original image,
before the image-net normalization.</p>
<p>I’m pretty sure that most of the methods that came after that, multiplied the tensor in the input to the model, after image-net normalization.</p>
<p>Both should be similar, but with difference that maybe black pixels (multiplying pre normalization) make the images look more different than the distribution of natural images, and maybe that has some effect.</p>
<p>No one is sharing the CAM evaluation code, and no one is commenting about that implementation detail in the papers, so I’m pretty sure the different papers are using differnt metrics ;-)</p>
<p>Before moving on to other metrics, lets take a first look at how to use these metrics in the pytorch-grad-cam package.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">models</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">cv2</span>
<span class="kn">import</span> <span class="nn">requests</span>
<span class="kn">from</span> <span class="nn">pytorch_grad_cam</span> <span class="kn">import</span> <span class="n">GradCAM</span>
<span class="kn">from</span> <span class="nn">pytorch_grad_cam.utils.model_targets</span> <span class="kn">import</span> <span class="n">ClassifierOutputTarget</span>
<span class="kn">from</span> <span class="nn">pytorch_grad_cam.utils.image</span> <span class="kn">import</span> <span class="n">show_cam_on_image</span><span class="p">,</span> \
    <span class="n">deprocess_image</span><span class="p">,</span> \
    <span class="n">preprocess_image</span>
<span class="kn">from</span> <span class="nn">PIL</span> <span class="kn">import</span> <span class="n">Image</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">resnet50</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="n">image_url</span> <span class="o">=</span> <span class="s2">&quot;https://th.bing.com/th/id/R.94b33a074b9ceeb27b1c7fba0f66db74?rik=wN27mvigyFlXGg&amp;riu=http</span><span class="si">%3a%2f%2f</span><span class="s2">images5.fanpop.com</span><span class="si">%2f</span><span class="s2">image</span><span class="si">%2f</span><span class="s2">photos</span><span class="si">%2f</span><span class="s2">31400000</span><span class="si">%2f</span><span class="s2">Bear-Wallpaper-bears-31446777-1600-1200.jpg&amp;ehk=oD0JPpRVTZZ6yizZtGQtnsBGK2pAap2xv3sU3A4bIMc</span><span class="si">%3d</span><span class="s2">&amp;risl=&amp;pid=ImgRaw&amp;r=0&quot;</span>
<span class="n">img</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">image_url</span><span class="p">,</span> <span class="n">stream</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">raw</span><span class="p">))</span>
<span class="n">img</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">resize</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="p">(</span><span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">))</span>
<span class="n">img</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">(</span><span class="n">img</span><span class="p">)</span> <span class="o">/</span> <span class="mi">255</span>
<span class="n">input_tensor</span> <span class="o">=</span> <span class="n">preprocess_image</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="p">[</span><span class="mf">0.485</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.406</span><span class="p">],</span> <span class="n">std</span><span class="o">=</span><span class="p">[</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">])</span>

<span class="c1"># The target for the CAM is the Bear category.</span>
<span class="c1"># As usual for classication, the target is the logit output</span>
<span class="c1"># before softmax, for that category.</span>
<span class="n">targets</span> <span class="o">=</span> <span class="p">[</span><span class="n">ClassifierOutputTarget</span><span class="p">(</span><span class="mi">295</span><span class="p">)]</span>
<span class="n">target_layers</span> <span class="o">=</span> <span class="p">[</span><span class="n">model</span><span class="o">.</span><span class="n">layer4</span><span class="p">]</span>
<span class="k">with</span> <span class="n">GradCAM</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">target_layers</span><span class="o">=</span><span class="n">target_layers</span><span class="p">)</span> <span class="k">as</span> <span class="n">cam</span><span class="p">:</span>
    <span class="n">grayscale_cams</span> <span class="o">=</span> <span class="n">cam</span><span class="p">(</span><span class="n">input_tensor</span><span class="o">=</span><span class="n">input_tensor</span><span class="p">,</span> <span class="n">targets</span><span class="o">=</span><span class="n">targets</span><span class="p">)</span>
    <span class="n">cam_image</span> <span class="o">=</span> <span class="n">show_cam_on_image</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">grayscale_cams</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:],</span> <span class="n">use_rgb</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">cam</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">(</span><span class="mi">255</span><span class="o">*</span><span class="n">grayscale_cams</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:])</span>
<span class="n">cam</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">merge</span><span class="p">([</span><span class="n">cam</span><span class="p">,</span> <span class="n">cam</span><span class="p">,</span> <span class="n">cam</span><span class="p">])</span>
<span class="n">images</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">(</span><span class="mi">255</span><span class="o">*</span><span class="n">img</span><span class="p">),</span> <span class="n">cam</span> <span class="p">,</span> <span class="n">cam_image</span><span class="p">))</span>
<span class="n">Image</span><span class="o">.</span><span class="n">fromarray</span><span class="p">(</span><span class="n">images</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/CAM Metrics And Tuning Tutorial_1_0.png" src="_images/CAM Metrics And Tuning Tutorial_1_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Now lets see how to evaluate this explanation:</span>
<span class="kn">from</span> <span class="nn">pytorch_grad_cam.metrics.cam_mult_image</span> <span class="kn">import</span> <span class="n">CamMultImageConfidenceChange</span>
<span class="kn">from</span> <span class="nn">pytorch_grad_cam.utils.model_targets</span> <span class="kn">import</span> <span class="n">ClassifierOutputSoftmaxTarget</span>

<span class="c1"># For the metrics we want to measure the change in the confidence, after softmax, that&#39;s why</span>
<span class="c1"># we use ClassifierOutputSoftmaxTarget.</span>
<span class="n">targets</span> <span class="o">=</span> <span class="p">[</span><span class="n">ClassifierOutputSoftmaxTarget</span><span class="p">(</span><span class="mi">295</span><span class="p">)]</span>
<span class="n">cam_metric</span> <span class="o">=</span> <span class="n">CamMultImageConfidenceChange</span><span class="p">()</span>
<span class="n">scores</span><span class="p">,</span> <span class="n">visualizations</span> <span class="o">=</span> <span class="n">cam_metric</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">,</span> <span class="n">grayscale_cams</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">return_visualization</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">score</span> <span class="o">=</span> <span class="n">scores</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">visualization</span> <span class="o">=</span> <span class="n">visualizations</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">transpose</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
<span class="n">visualization</span> <span class="o">=</span> <span class="n">deprocess_image</span><span class="p">(</span><span class="n">visualization</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;The confidence increase percent: </span><span class="si">{</span><span class="mi">100</span><span class="o">*</span><span class="n">score</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The visualization of the pertubated image for the metric:&quot;</span><span class="p">)</span>
<span class="n">Image</span><span class="o">.</span><span class="n">fromarray</span><span class="p">(</span><span class="n">visualization</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>The confidence increase percent: 0.010518915951251984
The visualization of the pertubated image for the metric:
</pre></div>
</div>
<img alt="_images/CAM Metrics And Tuning Tutorial_2_1.png" src="_images/CAM Metrics And Tuning Tutorial_2_1.png" />
</div>
</div>
<p>The confidence increase here is positive.</p>
<p>That’s a good sign - the CAM reduced noise from other parts of the image and retains the information that triggers the category output.</p>
<ul class="simple">
<li><p>The “drop in confidence” metric here from the gradcam++ paper would be 0 (since it’s negative).</p></li>
<li><p>The “increase in confidence” metric would be 1 (since there is an increase in confidence).
For completeness, lets see how we can use those metrics directly:</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pytorch_grad_cam.metrics.cam_mult_image</span> <span class="kn">import</span> <span class="n">DropInConfidence</span><span class="p">,</span> <span class="n">IncreaseInConfidence</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Drop in confidence&quot;</span><span class="p">,</span> <span class="n">DropInConfidence</span><span class="p">()(</span><span class="n">input_tensor</span><span class="p">,</span> <span class="n">grayscale_cams</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">model</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Increase in confidence&quot;</span><span class="p">,</span> <span class="n">IncreaseInConfidence</span><span class="p">()(</span><span class="n">input_tensor</span><span class="p">,</span> <span class="n">grayscale_cams</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">model</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Drop in confidence [0.]
Increase in confidence [1.]
</pre></div>
</div>
</div>
</div>
<p>Similarly, we could pertubate the image by deleting pixels with high values in the CAM.
In this case, we would WANT a larger drop in the confidence.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">inverse_cams</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">grayscale_cams</span>
<span class="n">scores</span><span class="p">,</span> <span class="n">visualizations</span> <span class="o">=</span> <span class="n">CamMultImageConfidenceChange</span><span class="p">()(</span><span class="n">input_tensor</span><span class="p">,</span> <span class="n">inverse_cams</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">return_visualization</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">score</span> <span class="o">=</span> <span class="n">scores</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">visualization</span> <span class="o">=</span> <span class="n">visualizations</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">transpose</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
<span class="n">visualization</span> <span class="o">=</span> <span class="n">deprocess_image</span><span class="p">(</span><span class="n">visualization</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;The confidence increase percent: </span><span class="si">{</span><span class="n">score</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The visualization of the pertubated image for the metric:&quot;</span><span class="p">)</span>
<span class="n">Image</span><span class="o">.</span><span class="n">fromarray</span><span class="p">(</span><span class="n">visualization</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>The confidence increase percent: 0.0002188194775953889
The visualization of the pertubated image for the metric:
</pre></div>
</div>
<img alt="_images/CAM Metrics And Tuning Tutorial_6_1.png" src="_images/CAM Metrics And Tuning Tutorial_6_1.png" />
</div>
</div>
</div>
</div>
</div>
<div class="tex2jax_ignore mathjax_ignore section" id="we-deleted-important-parts-how-come-it-became-more-confident">
<h1>We deleted important parts, how come it became more confident ?<a class="headerlink" href="#we-deleted-important-parts-how-come-it-became-more-confident" title="Permalink to this headline">#</a></h1>
<p>When we pertubate the supposedly impotant parts, the model actually becomes more confident than before.
Maybe the CAM explanation wasn’t telling us the whole story in the first place, and there are other parts that were important as well that is was missing.
This shows us the importance of using complementory metrics, and how these metrics can contradict each other.</p>
<p>Another problem here however is that the CAM itself has values that are medium range all over it:
after the pertubation, we can still see the bear in the image.
Getting the Image*CAM to work requires the CAM to have a distribution that’s more stretched.</p>
<p>This is the motivation for other methods that threshold the CAM and create binary masks.
Lets completely remove the highest scoring 25%, and see that the model confidence drops now.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">thresholded_cam</span> <span class="o">=</span> <span class="n">grayscale_cams</span> <span class="o">&lt;</span> <span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">grayscale_cams</span><span class="p">,</span> <span class="mi">75</span><span class="p">)</span>
<span class="n">scores</span><span class="p">,</span> <span class="n">visualizations</span> <span class="o">=</span> <span class="n">CamMultImageConfidenceChange</span><span class="p">()(</span><span class="n">input_tensor</span><span class="p">,</span> <span class="n">thresholded_cam</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">return_visualization</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">score</span> <span class="o">=</span> <span class="n">scores</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">visualization</span> <span class="o">=</span> <span class="n">visualizations</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">transpose</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
<span class="n">visualization</span> <span class="o">=</span> <span class="n">deprocess_image</span><span class="p">(</span><span class="n">visualization</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;The confidence increase: </span><span class="si">{</span><span class="n">score</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The visualization of the pertubated image for the metric:&quot;</span><span class="p">)</span>
<span class="n">Image</span><span class="o">.</span><span class="n">fromarray</span><span class="p">(</span><span class="n">visualization</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>The confidence increase: -0.001481899875216186
The visualization of the pertubated image for the metric:
</pre></div>
</div>
<img alt="_images/CAM Metrics And Tuning Tutorial_8_1.png" src="_images/CAM Metrics And Tuning Tutorial_8_1.png" />
</div>
</div>
<p>But the image above doesn’t look quite natural, does it ?</p>
<div class="section" id="remove-and-retrain-roar">
<h2>Remove and Retrain (ROAR)<a class="headerlink" href="#remove-and-retrain-roar" title="Permalink to this headline">#</a></h2>
<p><a class="reference external" href="https://arxiv.org/abs/1806.10758">https://arxiv.org/abs/1806.10758</a></p>
<p>When you pertubate the image by modifying the highest scoring regions, and the confidence decreases:</p>
<ul class="simple">
<li><p>Is it because the explanation is good and all of cues the model was using were now removed ?</p></li>
<li><p>Or is it because of the pertubation method itself that’s causing a distribution shift in the data: maybe the new image is so different than what the model expects, so un-natural, that the confidence drops.</p></li>
</ul>
<p><em>Maybe it thinks that all that gray above is a road, or an airplane.</em></p>
<p>The claim in this paper is that the high confidence drops the different methods show, is actually because of the latter.
When they pertubate the images by removing highest scoring pixels and then retrain, they the model is still actually much more accurate than expected.
Because of this, they argue that we should retrain on the pertubated images to be able to adapt to the pertubations. If the explanation method still scores high - we know we can trust it much more.</p>
<p>They also show that common methods (altough they focused more on gradient based method and not on CAM methods) are worse on this benchmark then classical computer vision edge detector (Sobel) that doesn’t depend on the model parameters at all.
So basically some methods that claim they are better than others, aren’t really.</p>
<p>Benchmarking against random explanations, or explanations that don’t depend on the model (like edge detection), is a very interesting idea in itself, so lets take a look at that.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pytorch_grad_cam.sobel_cam</span> <span class="kn">import</span> <span class="n">sobel_cam</span>

<span class="n">sobel_cam_grayscale</span> <span class="o">=</span> <span class="n">sobel_cam</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">(</span><span class="n">img</span> <span class="o">*</span> <span class="mi">255</span><span class="p">))</span>
<span class="n">thresholded_cam</span> <span class="o">=</span> <span class="n">sobel_cam_grayscale</span> <span class="o">&lt;</span> <span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">sobel_cam_grayscale</span><span class="p">,</span> <span class="mi">75</span><span class="p">)</span>

<span class="n">cam_metric</span> <span class="o">=</span> <span class="n">CamMultImageConfidenceChange</span><span class="p">()</span>
<span class="n">scores</span><span class="p">,</span> <span class="n">visualizations</span> <span class="o">=</span> <span class="n">cam_metric</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">,</span> <span class="p">[</span><span class="n">thresholded_cam</span><span class="p">],</span> <span class="n">targets</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">return_visualization</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">score</span> <span class="o">=</span> <span class="n">scores</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">visualization</span> <span class="o">=</span> <span class="n">visualizations</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">transpose</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
<span class="n">visualization</span> <span class="o">=</span> <span class="n">deprocess_image</span><span class="p">(</span><span class="n">visualization</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;The confidence increase: </span><span class="si">{</span><span class="n">score</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The visualization of the pertubated image for the metric:&quot;</span><span class="p">)</span>
<span class="n">sobel_cam_rgb</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">merge</span><span class="p">([</span><span class="n">sobel_cam_grayscale</span><span class="p">,</span> <span class="n">sobel_cam_grayscale</span><span class="p">,</span> <span class="n">sobel_cam_grayscale</span><span class="p">])</span>
<span class="n">Image</span><span class="o">.</span><span class="n">fromarray</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">sobel_cam_rgb</span><span class="p">,</span> <span class="n">visualization</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>The confidence increase: -0.0008427685825154185
The visualization of the pertubated image for the metric:
</pre></div>
</div>
<img alt="_images/CAM Metrics And Tuning Tutorial_10_1.png" src="_images/CAM Metrics And Tuning Tutorial_10_1.png" />
</div>
</div>
<p>Ok, good. So our CAM scores higher than a classic edge detector on this benchmark.
That’s good news !</p>
<p>Back to the ROAR method -
Re-training a model on the pertubated images is very expensive.
We don’t even always know in advance what explanation method we want to chose.
For many users this won’t be a practical approach. Altough if the stakes are high and you want to be 100% sure about the explanation, this is something to consider.</p>
<p>So what can we do?</p>
</div>
</div>
<div class="tex2jax_ignore mathjax_ignore section" id="sanity-checks-for-saliency-metrics">
<h1>Sanity Checks for Saliency Metrics<a class="headerlink" href="#sanity-checks-for-saliency-metrics" title="Permalink to this headline">#</a></h1>
<p><a class="reference external" href="https://arxiv.org/abs/1912.01451">https://arxiv.org/abs/1912.01451</a></p>
<p>This paper introduces a metric called “Area Over the Perturbation Curve” - AOPC, which is the average confidence drop over different removal percentiles.
(We will later call that MostRelevantFirstAverage or LeastRelevantFirstAverage since I think it’s a bit more explicit and clear, but it’s the same).</p>
<p>They check different imputation strategies:</p>
<ul class="simple">
<li><p>Replacing pixels that need to be deleted, by random values.</p></li>
<li><p>Replacing pixels that need to be deleted, by the mean (for R,G,B separately) in the image.</p></li>
<li><p>Removing the highest attention pixels first: Most Relevant First (MORF).</p></li>
<li><p>Removing the least attention pixels first: Least Relevant First (LERF).</p></li>
</ul>
<p>And then check how different algorithms differ on average acrross a dataset, but also for different individual images.
Ultimately we care about an individual image - we want to make sure the explanation we use for it is reliable.</p>
<p>The conclusion (in my own words) is that it’s a wild west.
Different imputation strategies give different results. MORF and LERF give different results for different algorithms, and basically measure different properties.
For the same image, it’s difficult to know in advance what explanation strategy will work best.</p>
<p>This means that going forward, we will need a combination of metrics, will need take in mind the imputation strategy, and will definately need to look at every image individually.</p>
</div>
<div class="tex2jax_ignore mathjax_ignore section" id="road-remove-and-debias">
<h1>ROAD: Remove and Debias<a class="headerlink" href="#road-remove-and-debias" title="Permalink to this headline">#</a></h1>
<p><a class="reference external" href="https://arxiv.org/abs/2202.00449">https://arxiv.org/abs/2202.00449</a></p>
<p>The claim in this paper is that the perbutbated image (they use the term “imputed image”) itself is leaking data.
Even the previous ROAR method can suffer from that.
They use a beutiful example so I’m going to just paste that here:</p>
<p><em>Imagine a two-class problem that consists of detecting whether an object is located on the
left or the right side of an image. A reasonable attribution
method masks out pixels on the left or the right depending
on the location of the object. In this case, the retraining
step can lead to a classifier that infers the class just from the
location of the masked out pixels and obtain high accuracy.</em></p>
<p>They further show that it’s easy to train models that predict what pixels are a result of the pertubation,
and that it’s possible to train models with surprising accuracy using just the binary masks.
So it’s possible to detect the mask, and then infer things from it.</p>
<p>To solve this they propose a pertubation method that’s more difficult to detect. And since it’s good and there is less of a distribution shift, training with ROAR doesn’t have an advantage any more: different metrics are more consistent with each other.</p>
<p>What they do is replace every pixel that needs to be removed with a weighted average of it’s neighbours. Since some of it’s neighbours might also need to be removed, we get system of linear equations that we have to solve, to find the new values of the pixels we want to replace.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pytorch_grad_cam.metrics.road</span> <span class="kn">import</span> <span class="n">ROADMostRelevantFirst</span>
<span class="n">cam_metric</span> <span class="o">=</span> <span class="n">ROADMostRelevantFirst</span><span class="p">(</span><span class="n">percentile</span><span class="o">=</span><span class="mi">75</span><span class="p">)</span>
<span class="n">scores</span><span class="p">,</span> <span class="n">visualizations</span> <span class="o">=</span> <span class="n">cam_metric</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">,</span> <span class="n">grayscale_cams</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">return_visualization</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">score</span> <span class="o">=</span> <span class="n">scores</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">visualization</span> <span class="o">=</span> <span class="n">visualizations</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">transpose</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
<span class="n">visualization</span> <span class="o">=</span> <span class="n">deprocess_image</span><span class="p">(</span><span class="n">visualization</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;The confidence increase when removing 25% of the image: </span><span class="si">{</span><span class="n">score</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="n">cam_metric</span> <span class="o">=</span> <span class="n">ROADMostRelevantFirst</span><span class="p">(</span><span class="n">percentile</span><span class="o">=</span><span class="mi">90</span><span class="p">)</span>
<span class="n">scores</span><span class="p">,</span> <span class="n">visualizations</span> <span class="o">=</span> <span class="n">cam_metric</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">,</span> <span class="n">grayscale_cams</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">return_visualization</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">score</span> <span class="o">=</span> <span class="n">scores</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">visualization_10</span> <span class="o">=</span> <span class="n">visualizations</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">transpose</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
<span class="n">visualization_10</span> <span class="o">=</span> <span class="n">deprocess_image</span><span class="p">(</span><span class="n">visualization_10</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;The confidence increase when removing 10% of the image: </span><span class="si">{</span><span class="n">score</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The visualizations:&quot;</span><span class="p">)</span>
<span class="n">Image</span><span class="o">.</span><span class="n">fromarray</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">visualization</span><span class="p">,</span> <span class="n">visualization_10</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>The confidence increase when removing 25% of the image: -0.0014768921537324786
The confidence increase when removing 10% of the image: -0.0012725943233817816
The visualizations:
</pre></div>
</div>
<img alt="_images/CAM Metrics And Tuning Tutorial_12_1.png" src="_images/CAM Metrics And Tuning Tutorial_12_1.png" />
</div>
</div>
<p>This is much better than replacing with the gray.
But to be honest it’s still quite distinguishable from the rest of the image since it’s so blurry.
So more work is needed to make this a convincing pertubation.
GANs can be useful here (and were used in the literature for this), but are computationally expensive.</p>
<p>How much from the image should we remove ?</p>
<p>That depends on the object size and varies, so it makes sense to try different percentiles and then take the average, if we want a more robust metric.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pytorch_grad_cam.metrics.road</span> <span class="kn">import</span> <span class="n">ROADMostRelevantFirstAverage</span>
<span class="n">cam_metric</span> <span class="o">=</span> <span class="n">ROADMostRelevantFirstAverage</span><span class="p">(</span><span class="n">percentiles</span><span class="o">=</span><span class="p">[</span><span class="mi">20</span><span class="p">,</span> <span class="mi">40</span><span class="p">,</span> <span class="mi">60</span><span class="p">,</span> <span class="mi">80</span><span class="p">])</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">cam_metric</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">,</span> <span class="n">grayscale_cams</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;The average confidence increase with ROAD accross 4 thresholds: </span><span class="si">{</span><span class="n">scores</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">cam_metric</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">,</span> <span class="p">[</span><span class="n">sobel_cam_grayscale</span><span class="p">],</span> <span class="n">targets</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;The average confidence increase for Sobel edge detection with ROAD accross 4 thresholds: </span><span class="si">{</span><span class="n">scores</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>The average confidence increase with ROAD accross 4 thresholds: -0.0013600271195173264
The average confidence increase for Sobel edge detection with ROAD accross 4 thresholds: 0.00018378457752987742
</pre></div>
</div>
</div>
</div>
<p>How would this metric look if we just zerod out the cam completely ?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cam_metric</span> <span class="o">=</span> <span class="n">ROADMostRelevantFirstAverage</span><span class="p">(</span><span class="n">percentiles</span><span class="o">=</span><span class="p">[</span><span class="mi">20</span><span class="p">,</span> <span class="mi">40</span><span class="p">,</span> <span class="mi">60</span><span class="p">,</span> <span class="mi">80</span><span class="p">])</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">cam_metric</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">,</span> <span class="n">grayscale_cams</span> <span class="o">*</span> <span class="mi">0</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Empty CAM, Most relevant first avg confidence increase with ROAD accross 4 thresholds: </span><span class="si">{</span><span class="n">scores</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Empty CAM, Most relevant first avg confidence increase with ROAD accross 4 thresholds: -0.0014464930864050984
</pre></div>
</div>
</div>
</div>
<p>Uh oh.
Of course the drop in confidence will be huge if we corrupt the CAM completely.
To balance that we can see what happens when we delete the least relevant first, we would want the confidence increase to be larger.
And for an empty CAM as baseline - the confidence increase should be very negative (bad) for LeastRelevantFirst.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pytorch_grad_cam.metrics.road</span> <span class="kn">import</span> <span class="n">ROADLeastRelevantFirstAverage</span><span class="p">,</span> <span class="n">ROADMostRelevantFirstAverage</span>
<span class="n">cam_metric</span> <span class="o">=</span> <span class="n">ROADLeastRelevantFirstAverage</span><span class="p">(</span><span class="n">percentiles</span><span class="o">=</span><span class="p">[</span><span class="mi">20</span><span class="p">,</span> <span class="mi">40</span><span class="p">,</span> <span class="mi">60</span><span class="p">,</span> <span class="mi">80</span><span class="p">])</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">cam_metric</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">,</span> <span class="n">grayscale_cams</span> <span class="o">*</span> <span class="mi">0</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Empty CAM, Least relevant first avg confidence increase with ROAD accross 4 thresholds: </span><span class="si">{</span><span class="n">scores</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Empty CAM, Least relevant first avg confidence increase with ROAD accross 4 thresholds: -0.001446255948394537
</pre></div>
</div>
</div>
</div>
<p>Good.
To finalize this, lets use a custom single metric that is a combination of Least Relevant First and Most Relevant First:</p>
<p>(Least Relevant First - Most Relevant First) / 2, accross different thresholds.</p>
<p>This way we get a single metric and don’t have to inspect both.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pytorch_grad_cam.metrics.road</span> <span class="kn">import</span> <span class="n">ROADCombined</span>
<span class="n">cam_metric</span> <span class="o">=</span> <span class="n">ROADCombined</span><span class="p">(</span><span class="n">percentiles</span><span class="o">=</span><span class="p">[</span><span class="mi">20</span><span class="p">,</span> <span class="mi">40</span><span class="p">,</span> <span class="mi">60</span><span class="p">,</span> <span class="mi">80</span><span class="p">])</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">cam_metric</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">,</span> <span class="n">grayscale_cams</span> <span class="o">*</span> <span class="mi">0</span><span class="p">,</span> <span class="n">targets</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Empty CAM, Combined metric avg confidence increase with ROAD accross 4 thresholds (positive is better): </span><span class="si">{</span><span class="n">scores</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Empty CAM, Combined metric avg confidence increase with ROAD accross 4 thresholds (positive is better): -1.5791738405823708e-07
</pre></div>
</div>
</div>
</div>
<p>So we have ethods that can rank our model explanations.
We saw we can compare that against a sobel edge detector as a sanity check to see we’re better.</p>
<p>Lets see how to use this to get better explanations.</p>
<p>We will also use a toy RandomCAM that generates CAMs with random uniform values in the range [-1, 1] for the spatial activations.
If our CAM methods are that smart, they should be much better than it, on average.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pytorch_grad_cam</span> <span class="kn">import</span> <span class="n">GradCAM</span><span class="p">,</span> <span class="n">GradCAMPlusPlus</span><span class="p">,</span> <span class="n">EigenGradCAM</span><span class="p">,</span> <span class="n">AblationCAM</span><span class="p">,</span> <span class="n">RandomCAM</span>

<span class="c1"># Showing the metrics on top of the CAM : </span>
<span class="k">def</span> <span class="nf">visualize_score</span><span class="p">(</span><span class="n">visualization</span><span class="p">,</span> <span class="n">score</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">percentiles</span><span class="p">):</span>
    <span class="n">visualization</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">putText</span><span class="p">(</span><span class="n">visualization</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">20</span><span class="p">),</span> 
                                <span class="n">cv2</span><span class="o">.</span><span class="n">FONT_HERSHEY_SIMPLEX</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="p">(</span><span class="mi">255</span><span class="p">,</span><span class="mi">255</span><span class="p">,</span><span class="mi">255</span><span class="p">),</span> <span class="mi">1</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">LINE_AA</span><span class="p">)</span>
    <span class="n">visualization</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">putText</span><span class="p">(</span><span class="n">visualization</span><span class="p">,</span> <span class="s2">&quot;(Least first - Most first)/2&quot;</span><span class="p">,</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">40</span><span class="p">),</span> 
                                <span class="n">cv2</span><span class="o">.</span><span class="n">FONT_HERSHEY_SIMPLEX</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="p">(</span><span class="mi">255</span><span class="p">,</span><span class="mi">255</span><span class="p">,</span><span class="mi">255</span><span class="p">),</span> <span class="mi">1</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">LINE_AA</span><span class="p">)</span>
    <span class="n">visualization</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">putText</span><span class="p">(</span><span class="n">visualization</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;Percentiles: </span><span class="si">{</span><span class="n">percentiles</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">55</span><span class="p">),</span> 
                                <span class="n">cv2</span><span class="o">.</span><span class="n">FONT_HERSHEY_SIMPLEX</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="p">(</span><span class="mi">255</span><span class="p">,</span><span class="mi">255</span><span class="p">,</span><span class="mi">255</span><span class="p">),</span> <span class="mi">1</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">LINE_AA</span><span class="p">)</span>    
    <span class="n">visualization</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">putText</span><span class="p">(</span><span class="n">visualization</span><span class="p">,</span> <span class="s2">&quot;Remove and Debias&quot;</span><span class="p">,</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">70</span><span class="p">),</span> 
                                <span class="n">cv2</span><span class="o">.</span><span class="n">FONT_HERSHEY_SIMPLEX</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="p">(</span><span class="mi">255</span><span class="p">,</span><span class="mi">255</span><span class="p">,</span><span class="mi">255</span><span class="p">),</span> <span class="mi">1</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">LINE_AA</span><span class="p">)</span> 
    <span class="n">visualization</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">putText</span><span class="p">(</span><span class="n">visualization</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">score</span><span class="si">:</span><span class="s2">.5f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">85</span><span class="p">),</span> 
                                <span class="n">cv2</span><span class="o">.</span><span class="n">FONT_HERSHEY_SIMPLEX</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">,</span> <span class="p">(</span><span class="mi">255</span><span class="p">,</span><span class="mi">255</span><span class="p">,</span><span class="mi">255</span><span class="p">),</span> <span class="mi">1</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">LINE_AA</span><span class="p">)</span>    
    <span class="k">return</span> <span class="n">visualization</span>
    
<span class="k">def</span> <span class="nf">benchmark</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">,</span> <span class="n">target_layers</span><span class="p">,</span> <span class="n">eigen_smooth</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">aug_smooth</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">category</span><span class="o">=</span><span class="mi">281</span><span class="p">):</span>
    <span class="n">methods</span> <span class="o">=</span> <span class="p">[(</span><span class="s2">&quot;GradCAM&quot;</span><span class="p">,</span> <span class="n">GradCAM</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">target_layers</span><span class="o">=</span><span class="n">target_layers</span><span class="p">,</span> <span class="n">use_cuda</span><span class="o">=</span><span class="kc">True</span><span class="p">)),</span>
               <span class="p">(</span><span class="s2">&quot;GradCAM++&quot;</span><span class="p">,</span> <span class="n">GradCAMPlusPlus</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">target_layers</span><span class="o">=</span><span class="n">target_layers</span><span class="p">,</span> <span class="n">use_cuda</span><span class="o">=</span><span class="kc">True</span><span class="p">)),</span>
               <span class="p">(</span><span class="s2">&quot;EigenGradCAM&quot;</span><span class="p">,</span> <span class="n">EigenGradCAM</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">target_layers</span><span class="o">=</span><span class="n">target_layers</span><span class="p">,</span> <span class="n">use_cuda</span><span class="o">=</span><span class="kc">True</span><span class="p">)),</span>
               <span class="p">(</span><span class="s2">&quot;AblationCAM&quot;</span><span class="p">,</span> <span class="n">AblationCAM</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">target_layers</span><span class="o">=</span><span class="n">target_layers</span><span class="p">,</span> <span class="n">use_cuda</span><span class="o">=</span><span class="kc">True</span><span class="p">)),</span>
               <span class="p">(</span><span class="s2">&quot;RandomCAM&quot;</span><span class="p">,</span> <span class="n">RandomCAM</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">target_layers</span><span class="o">=</span><span class="n">target_layers</span><span class="p">,</span> <span class="n">use_cuda</span><span class="o">=</span><span class="kc">True</span><span class="p">))]</span>

    <span class="n">cam_metric</span> <span class="o">=</span> <span class="n">ROADCombined</span><span class="p">(</span><span class="n">percentiles</span><span class="o">=</span><span class="p">[</span><span class="mi">20</span><span class="p">,</span> <span class="mi">40</span><span class="p">,</span> <span class="mi">60</span><span class="p">,</span> <span class="mi">80</span><span class="p">])</span>
    <span class="n">targets</span> <span class="o">=</span> <span class="p">[</span><span class="n">ClassifierOutputTarget</span><span class="p">(</span><span class="n">category</span><span class="p">)]</span>
    <span class="n">metric_targets</span> <span class="o">=</span> <span class="p">[</span><span class="n">ClassifierOutputSoftmaxTarget</span><span class="p">(</span><span class="n">category</span><span class="p">)]</span>
    
    <span class="n">visualizations</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">percentiles</span> <span class="o">=</span> <span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">90</span><span class="p">]</span>
    <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">cam_method</span> <span class="ow">in</span> <span class="n">methods</span><span class="p">:</span>
        <span class="k">with</span> <span class="n">cam_method</span><span class="p">:</span>
            <span class="n">attributions</span> <span class="o">=</span> <span class="n">cam_method</span><span class="p">(</span><span class="n">input_tensor</span><span class="o">=</span><span class="n">input_tensor</span><span class="p">,</span> 
                                      <span class="n">targets</span><span class="o">=</span><span class="n">targets</span><span class="p">,</span> <span class="n">eigen_smooth</span><span class="o">=</span><span class="n">eigen_smooth</span><span class="p">,</span> <span class="n">aug_smooth</span><span class="o">=</span><span class="n">aug_smooth</span><span class="p">)</span>
        <span class="n">attribution</span> <span class="o">=</span> <span class="n">attributions</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="p">:]</span>    
        <span class="n">scores</span> <span class="o">=</span> <span class="n">cam_metric</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">,</span> <span class="n">attributions</span><span class="p">,</span> <span class="n">metric_targets</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
        <span class="n">score</span> <span class="o">=</span> <span class="n">scores</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">visualization</span> <span class="o">=</span> <span class="n">show_cam_on_image</span><span class="p">(</span><span class="n">cat_and_dog</span><span class="p">,</span> <span class="n">attribution</span><span class="p">,</span> <span class="n">use_rgb</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">visualization</span> <span class="o">=</span> <span class="n">visualize_score</span><span class="p">(</span><span class="n">visualization</span><span class="p">,</span> <span class="n">score</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">percentiles</span><span class="p">)</span>
        <span class="n">visualizations</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">visualization</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">Image</span><span class="o">.</span><span class="n">fromarray</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">(</span><span class="n">visualizations</span><span class="p">))</span>

<span class="n">cat_and_dog_image_url</span> <span class="o">=</span> <span class="s2">&quot;https://raw.githubusercontent.com/jacobgil/pytorch-grad-cam/master/examples/both.png&quot;</span>
<span class="n">cat_and_dog</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">cat_and_dog_image_url</span><span class="p">,</span> <span class="n">stream</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">raw</span><span class="p">))</span>
<span class="n">cat_and_dog</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">(</span><span class="n">cat_and_dog</span><span class="p">)</span> <span class="o">/</span> <span class="mi">255</span>
<span class="n">input_tensor</span> <span class="o">=</span> <span class="n">preprocess_image</span><span class="p">(</span><span class="n">cat_and_dog</span><span class="p">,</span> <span class="n">mean</span><span class="o">=</span><span class="p">[</span><span class="mf">0.485</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.406</span><span class="p">],</span> <span class="n">std</span><span class="o">=</span><span class="p">[</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">])</span>
<span class="n">target_layers</span> <span class="o">=</span> <span class="p">[</span><span class="n">model</span><span class="o">.</span><span class="n">layer4</span><span class="p">]</span>

<span class="n">model</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
<span class="n">input_tensor</span> <span class="o">=</span> <span class="n">input_tensor</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">benchmark</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">,</span> <span class="n">target_layers</span><span class="p">,</span> <span class="n">eigen_smooth</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">aug_smooth</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 64/64 [00:05&lt;00:00, 11.38it/s]
</pre></div>
</div>
<img alt="_images/CAM Metrics And Tuning Tutorial_22_1.png" src="_images/CAM Metrics And Tuning Tutorial_22_1.png" />
</div>
</div>
<p>So EigenGradCAM is a clear winner, not unsurprisingly since it also looks smoother.</p>
<p>What about if we use an earlier layer with lower level features?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">target_layers</span> <span class="o">=</span> <span class="p">[</span><span class="n">model</span><span class="o">.</span><span class="n">layer4</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">]]</span>
<span class="n">benchmark</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">,</span> <span class="n">target_layers</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 64/64 [00:06&lt;00:00, 10.47it/s]
</pre></div>
</div>
<img alt="_images/CAM Metrics And Tuning Tutorial_24_1.png" src="_images/CAM Metrics And Tuning Tutorial_24_1.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">benchmark</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">,</span> <span class="n">target_layers</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 64/64 [00:05&lt;00:00, 10.99it/s]
</pre></div>
</div>
<img alt="_images/CAM Metrics And Tuning Tutorial_25_1.png" src="_images/CAM Metrics And Tuning Tutorial_25_1.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Let&#39;s look how it looks for one of the dog categories (that the model is much less confident about)</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">benchmark</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">,</span> <span class="n">target_layers</span><span class="p">,</span> <span class="n">category</span><span class="o">=</span><span class="mi">246</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 64/64 [00:06&lt;00:00, 10.24it/s]
</pre></div>
</div>
<img alt="_images/CAM Metrics And Tuning Tutorial_26_1.png" src="_images/CAM Metrics And Tuning Tutorial_26_1.png" />
</div>
</div>
<p>So using this metric we can see that:</p>
<ul class="simple">
<li><p>The different methods perform quite different.</p></li>
<li><p>You can use the metric to tune parameters like which layer or explainability method to use.</p></li>
<li><p>The explanations are quite different between the different methods.</p></li>
<li><p>A Random CAM isn’t always that behind some of the methods, but still they are much better than random..
In any case we need to be suspicious about the results and double check them against benchmarks like RandomCAM or Sobel, before extracting too many insights from them.</p></li>
</ul>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="Pixel%20Attribution%20for%20embeddings.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Tutorial: Concept Activation Maps</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="vision_transformers.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">How does it work with Vision Transformers</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Jacob Gildenblat<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>